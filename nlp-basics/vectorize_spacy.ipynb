{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing with SpaCy\n",
    "\n",
    "In addition to SciKit Learn, SpaCy also has methods for vectorizing textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", Dave, watched, forest, burned, hill, ,, \n",
      ", miles, house]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Dave watched as the forest burned up on the hill,\n",
    "only a few miles from his house. The car had\n",
    "been hastily packed and Marta was inside trying to round\n",
    "up the last of the pets. \"Where could she be?\" he wondered\n",
    "as he continued to wait for Marta to appear with the pets.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenize and put into a list in one line\n",
    "token_list = [token for token in doc]\n",
    "# Remove stop words in one line using hte .is_stop attribute\n",
    "filtered_tokens = [token for token in doc if not token.is_stop]\n",
    "print(filtered_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8371646 ,  1.4529226 , -1.6147211 ,  0.678362  , -0.6594443 ,\n",
       "        1.6417935 ,  0.5796405 ,  2.3021278 , -0.13260496,  0.5750932 ,\n",
       "        1.5654886 , -0.6938864 , -0.59607106, -1.5377437 ,  1.9425622 ,\n",
       "       -2.4552505 ,  1.2321601 ,  1.0434952 , -1.5102385 , -0.5787632 ,\n",
       "        0.12055647,  3.6501784 ,  2.6160972 , -0.5710199 , -1.5221789 ,\n",
       "        0.00629176,  0.22760668, -1.922073  , -1.6252862 , -4.226225  ,\n",
       "       -3.495663  , -3.312053  ,  0.81387717, -0.00677544, -0.11603224,\n",
       "        1.4620426 ,  3.0751472 ,  0.35958546, -0.22527039, -2.743926  ,\n",
       "        1.269633  ,  4.606786  ,  0.34034157, -2.1272311 ,  1.2619178 ,\n",
       "       -4.209798  ,  5.452852  ,  1.6940253 , -2.5972986 ,  0.95049495,\n",
       "       -1.910578  , -2.374927  , -1.4227567 , -2.2528825 , -1.799806  ,\n",
       "        1.607501  ,  2.9914255 ,  2.8065152 , -1.2510269 , -0.54964066,\n",
       "       -0.49980402, -1.3882618 , -0.470479  , -2.9670253 ,  1.7884955 ,\n",
       "        4.5282774 , -1.2602427 , -0.14885521,  1.0419178 , -0.08892632,\n",
       "       -1.138275  ,  2.242618  ,  1.5077229 , -1.5030195 ,  2.528098  ,\n",
       "       -1.6761329 ,  0.16694719,  2.123961  ,  0.02546412,  0.38754445,\n",
       "        0.8911977 , -0.07678384, -2.0690763 , -1.1211847 ,  1.4821006 ,\n",
       "        1.1989193 ,  2.1933236 ,  0.5296372 ,  3.0646474 , -1.7223308 ,\n",
       "       -1.3634219 , -0.47471118, -1.7648507 ,  3.565178  , -2.394205  ,\n",
       "       -1.3800384 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the second token in the filtered_tokens list\n",
    "filtered_tokens[1].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
